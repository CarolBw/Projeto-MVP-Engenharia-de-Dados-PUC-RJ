# -*- coding: utf-8 -*-
"""DAGs-Extract-Transform.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TPwxRh29ctJ81MLQAc8e-yccnGlt52yK

DAG Extração e Transformação

Descrição:
Esta DAG realiza a extração de dados financeiros e meteorológicos, limpeza, mesclagem e armazenamento no Google Cloud Storage.

Tarefas:
- extract_usd_aed: Extrai dados históricos do par USD/AED do Yahoo Finance.
- extract_usd_brl: Extrai dados históricos do par USD/BRL do Yahoo Finance.
- clean_usd_aed: Realiza limpeza e transformação nos dados do par USD/AED.
- clean_usd_brl: Realiza limpeza e transformação nos dados do par USD/BRL.
- extract_weather_dubai: Extrai dados diários de temperatura para Dubai.
- clean_weather_dubai: Realiza limpeza e transformação nos dados de temperatura para Dubai.
- merge_finance_weather_data: Mescla os dados financeiros e de temperatura.
- save_to_gcs: Salva os dados mesclados no Google Cloud Storage.
"""

from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime
from datetime import timedelta
import yfinance as yf
from meteostat import Point, Daily
import pandas as pd
from google.cloud import storage
import io

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 7, 12),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'finance_and_weather_data_pipeline',
    default_args=default_args,
    description='A DAG to extract finance and weather data, clean, merge, and store in GCS',
    schedule_interval=timedelta(days=1),
)

# Definindo as funções que serão utilizadas nas tasks da DAG

def extract_finance_data(ticker, start_date, end_date):
    try:
        df = yf.download(ticker, start=start_date, end=end_date)
        if df.empty:
            raise ValueError(f"No data found for ticker {ticker}")
        return df
    except Exception as e:
        print(f"Error extracting data for ticker {ticker}: {e}")
        return None

def clean_finance_data(df, prefix):
    try:
        columns_rename = {
            'Close': f'{prefix}_Close',
            'High': f'{prefix}_High',
            'Low': f'{prefix}_Low',
            'Open': f'{prefix}_Open'
        }
        df = df[['Close', 'High', 'Low', 'Open']].rename(columns=columns_rename)
        df['Date'] = df.index
        df['Date'] = pd.to_datetime(df['Date'])
        df.reset_index(drop=True, inplace=True)
        return df
    except Exception as e:
        print(f'Error during data cleaning for {prefix}: {str(e)}')
        return None

def extract_weather_data(latitude, longitude, start_date, end_date):
    try:
        location = Point(latitude, longitude)
        df = Daily(location, start_date, end_date).fetch()
        return df
    except Exception as e:
        print(f'Error extracting weather data: {str(e)}')
        return None

def clean_weather_data(df):
    try:
        df['Date'] = df.index
        df.reset_index(inplace=True)
        df = df[['Date', 'tmax', 'tmin', 'tavg']]
        df.rename(columns={'tmax': 'Temp_Max_Dubai', 'tmin': 'Temp_Min_Dubai', 'tavg': 'Temp_Media_Dubai'}, inplace=True)
        return df
    except Exception as e:
        print(f'Error during weather data cleaning: {str(e)}')
        return None

def merge_dataframes(df1, df2):
    try:
        df_merged = pd.merge(df1, df2, on='Date', how='inner')
        return df_merged
    except Exception as e:
        print(f'Error merging dataframes: {str(e)}')
        return None

def save_to_gcs(dataframe, bucket_name, file_name):
    try:
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        temp_csv_file = '/tmp/temp_data.csv'
        dataframe.to_csv(temp_csv_file, index=False)
        blob = bucket.blob(file_name)
        blob.upload_from_filename(temp_csv_file)
        print(f'Data saved to GCS bucket {bucket_name}, file {file_name}.')
    except Exception as e:
        print(f'Error saving data to GCS bucket {bucket_name}, file {file_name}: {str(e)}')

# Definindo as tasks da DAG

extract_usd_aed_task = PythonOperator(
    task_id='extract_usd_aed',
    python_callable=extract_finance_data,
    op_args=['USDAED=X', datetime(2013, 1, 1), datetime(2024, 1, 1)],
    dag=dag,
)

extract_usd_brl_task = PythonOperator(
    task_id='extract_usd_brl',
    python_callable=extract_finance_data,
    op_args=['USDBRL=X', datetime(2013, 1, 1), datetime(2024, 1, 1)],
    dag=dag,
)

clean_usd_aed_task = PythonOperator(
    task_id='clean_usd_aed',
    python_callable=clean_finance_data,
    op_args=[],
    provide_context=True,
    dag=dag,
)

clean_usd_brl_task = PythonOperator(
    task_id='clean_usd_brl',
    python_callable=clean_finance_data,
    op_args=[],
    provide_context=True,
    dag=dag,
)

extract_weather_task = PythonOperator(
    task_id='extract_weather_dubai',
    python_callable=extract_weather_data,
    op_args=[25.276987, 55.296249, datetime(2013, 1, 1), datetime(2024, 1, 1)],
    dag=dag,
)

clean_weather_task = PythonOperator(
    task_id='clean_weather_dubai',
    python_callable=clean_weather_data,
    op_args=[],
    provide_context=True,
    dag=dag,
)

merge_data_task = PythonOperator(
    task_id='merge_finance_weather_data',
    python_callable=merge_dataframes,
    op_args=[],
    provide_context=True,
    dag=dag,
)

save_to_gcs_task = PythonOperator(
    task_id='save_to_gcs',
    python_callable=save_to_gcs,
    op_args=[],
    provide_context=True,
    dag=dag,
)

# Definindo as dependências entre as tasks

extract_usd_aed_task >> clean_usd_aed_task
extract_usd_brl_task >> clean_usd_brl_task
extract_weather_task >> clean_weather_task
[clean_usd_aed_task, clean_usd_brl_task] >> merge_data_task
[clean_weather_task, merge_data_task] >> save_to_gcs_task